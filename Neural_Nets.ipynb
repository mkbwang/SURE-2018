{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangmk/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as roc\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_csv('/home/wangmk/UM/Research/SURE/cleaned_data/full_cleaned_data.csv')\n",
    "alldata['Agree'] = ~(alldata['True_state']^alldata['Alert'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>True_state</th>\n",
       "      <th>Alert</th>\n",
       "      <th>Identification</th>\n",
       "      <th>First_toggle_time</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Attention</th>\n",
       "      <th>Click</th>\n",
       "      <th>Top_Left_Enemy</th>\n",
       "      <th>Top_Right_Enemy</th>\n",
       "      <th>Bottom_Left_Enemy</th>\n",
       "      <th>Bottom_Right_Enemy</th>\n",
       "      <th>Top_Left_Dark</th>\n",
       "      <th>Top_Right_Dark</th>\n",
       "      <th>Bottom_Left_Dark</th>\n",
       "      <th>Bottom_Right_Dark</th>\n",
       "      <th>Agree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4179</td>\n",
       "      <td>65.244487</td>\n",
       "      <td>0.914573</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3653</td>\n",
       "      <td>67.293907</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2186</td>\n",
       "      <td>100.119892</td>\n",
       "      <td>0.854271</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3412</td>\n",
       "      <td>33.403009</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4514</td>\n",
       "      <td>70.063858</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trial  True_state  Alert  Identification  First_toggle_time         RMS  \\\n",
       "0      0        True   True            True               4179   65.244487   \n",
       "1      1       False  False           False               3653   67.293907   \n",
       "2      2       False   True           False               2186  100.119892   \n",
       "3      3       False  False           False               3412   33.403009   \n",
       "4      4       False  False           False               4514   70.063858   \n",
       "\n",
       "   Attention  Click  Top_Left_Enemy  Top_Right_Enemy  Bottom_Left_Enemy  \\\n",
       "0   0.914573      2            True            False              False   \n",
       "1   0.895000      2           False            False              False   \n",
       "2   0.854271      2           False            False              False   \n",
       "3   0.889447      2           False            False              False   \n",
       "4   0.929648      2           False            False              False   \n",
       "\n",
       "   Bottom_Right_Enemy  Top_Left_Dark  Top_Right_Dark  Bottom_Left_Dark  \\\n",
       "0               False          False            True              True   \n",
       "1               False           True            True              True   \n",
       "2               False           True           False              True   \n",
       "3               False           True           False              True   \n",
       "4               False           True            True              True   \n",
       "\n",
       "   Bottom_Right_Dark  Agree  \n",
       "0               True   True  \n",
       "1               True   True  \n",
       "2              False  False  \n",
       "3               True   True  \n",
       "4               True   True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal = alldata[alldata['RMS']>60]\n",
    "normal = alldata[alldata['RMS']<=60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = abnormal.append(normal.sample(n=160,random_state=40))\n",
    "newdata['performance'] = newdata['RMS'] <= 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata['First_toggle_time'] = newdata['First_toggle_time']/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdata.drop(['RMS','performance','Click'],axis=1)\n",
    "y = newdata['performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_shape = (15,)))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 224 samples, validate on 96 samples\n",
      "Epoch 1/30\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6915 - acc: 0.6071 - val_loss: 1.2180 - val_acc: 0.0625\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 0s 170us/step - loss: 0.6719 - acc: 0.6875 - val_loss: 0.9975 - val_acc: 0.0208\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 0s 172us/step - loss: 0.6461 - acc: 0.7098 - val_loss: 0.9118 - val_acc: 0.0000e+00\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 0s 245us/step - loss: 0.6333 - acc: 0.7143 - val_loss: 1.0361 - val_acc: 0.0000e+00\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 0s 205us/step - loss: 0.6186 - acc: 0.7143 - val_loss: 1.0727 - val_acc: 0.0000e+00\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 0s 196us/step - loss: 0.6089 - acc: 0.7143 - val_loss: 1.0560 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f002e18a8d0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_neuralnets = to_categorical(y)\n",
    "model.fit(X,y_neuralnets,epochs=30,validation_split=0.3,callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([2,5,10,50,70,90,120,400,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 5.9024 - acc: 0.5196 - val_loss: 7.1571 - val_acc: 0.4231\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 263us/step - loss: 5.6520 - acc: 0.5196 - val_loss: 6.8396 - val_acc: 0.4231\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 261us/step - loss: 5.2733 - acc: 0.5196 - val_loss: 6.2264 - val_acc: 0.4231\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 234us/step - loss: 4.6772 - acc: 0.5098 - val_loss: 5.1645 - val_acc: 0.4231\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 239us/step - loss: 3.6465 - acc: 0.5049 - val_loss: 3.5174 - val_acc: 0.4615\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 262us/step - loss: 2.3607 - acc: 0.4951 - val_loss: 1.8814 - val_acc: 0.4423\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 267us/step - loss: 1.2005 - acc: 0.4755 - val_loss: 0.7397 - val_acc: 0.4808\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 239us/step - loss: 0.7597 - acc: 0.4951 - val_loss: 0.7872 - val_acc: 0.6154\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 272us/step - loss: 0.9242 - acc: 0.5098 - val_loss: 0.8005 - val_acc: 0.6154\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 215us/step - loss: 0.8202 - acc: 0.5294 - val_loss: 0.6629 - val_acc: 0.6346\n",
      "Epoch 11/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.7161 - acc: 0.4902 - val_loss: 0.7036 - val_acc: 0.4615\n",
      "Epoch 12/30\n",
      "204/204 [==============================] - 0s 271us/step - loss: 0.7549 - acc: 0.4608 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 13/30\n",
      "204/204 [==============================] - 0s 250us/step - loss: 0.7267 - acc: 0.4853 - val_loss: 0.6577 - val_acc: 0.5962\n",
      "Epoch 14/30\n",
      "204/204 [==============================] - 0s 286us/step - loss: 0.7143 - acc: 0.5490 - val_loss: 0.6528 - val_acc: 0.6154\n",
      "Epoch 15/30\n",
      "204/204 [==============================] - 0s 264us/step - loss: 0.7086 - acc: 0.5490 - val_loss: 0.6508 - val_acc: 0.6538\n",
      "Epoch 16/30\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.6928 - acc: 0.5441 - val_loss: 0.6493 - val_acc: 0.6346\n",
      "Epoch 17/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 0.6803 - acc: 0.5049 - val_loss: 0.6609 - val_acc: 0.6154\n",
      "Epoch 18/30\n",
      "204/204 [==============================] - 0s 257us/step - loss: 0.6832 - acc: 0.5196 - val_loss: 0.6505 - val_acc: 0.6346\n",
      "Epoch 19/30\n",
      "204/204 [==============================] - 0s 250us/step - loss: 0.6754 - acc: 0.5196 - val_loss: 0.6467 - val_acc: 0.6538\n",
      "Epoch 20/30\n",
      "204/204 [==============================] - 0s 237us/step - loss: 0.6728 - acc: 0.5343 - val_loss: 0.6459 - val_acc: 0.6538\n",
      "Epoch 21/30\n",
      "204/204 [==============================] - 0s 246us/step - loss: 0.6684 - acc: 0.5343 - val_loss: 0.6457 - val_acc: 0.6538\n",
      "Epoch 22/30\n",
      "204/204 [==============================] - 0s 277us/step - loss: 0.6660 - acc: 0.5343 - val_loss: 0.6493 - val_acc: 0.6538\n",
      "Epoch 23/30\n",
      "204/204 [==============================] - 0s 335us/step - loss: 0.6656 - acc: 0.5392 - val_loss: 0.6451 - val_acc: 0.6538\n",
      "Epoch 24/30\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.6667 - acc: 0.5441 - val_loss: 0.6527 - val_acc: 0.6154\n",
      "Epoch 25/30\n",
      "204/204 [==============================] - 0s 324us/step - loss: 0.6598 - acc: 0.5539 - val_loss: 0.6444 - val_acc: 0.6538\n",
      "Epoch 26/30\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.6577 - acc: 0.5637 - val_loss: 0.6458 - val_acc: 0.6538\n",
      "Epoch 27/30\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.6548 - acc: 0.5686 - val_loss: 0.6459 - val_acc: 0.6538\n",
      "Epoch 28/30\n",
      "204/204 [==============================] - 0s 261us/step - loss: 0.6541 - acc: 0.5882 - val_loss: 0.6493 - val_acc: 0.6538\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 3.5677 - acc: 0.4902 - val_loss: 3.9712 - val_acc: 0.5192\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 229us/step - loss: 3.1010 - acc: 0.5049 - val_loss: 3.3248 - val_acc: 0.5192\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 316us/step - loss: 2.5740 - acc: 0.5196 - val_loss: 2.6692 - val_acc: 0.5192\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 264us/step - loss: 2.0543 - acc: 0.5196 - val_loss: 2.0451 - val_acc: 0.5385\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 276us/step - loss: 1.5661 - acc: 0.5196 - val_loss: 1.5017 - val_acc: 0.5385\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 280us/step - loss: 1.2034 - acc: 0.5196 - val_loss: 1.2359 - val_acc: 0.5385\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 1.0280 - acc: 0.5245 - val_loss: 1.0789 - val_acc: 0.5385\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 246us/step - loss: 0.9080 - acc: 0.5245 - val_loss: 0.9544 - val_acc: 0.5192\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 243us/step - loss: 0.8142 - acc: 0.5490 - val_loss: 0.8632 - val_acc: 0.5385\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 0.7560 - acc: 0.5637 - val_loss: 0.7938 - val_acc: 0.5192\n",
      "Epoch 11/30\n",
      "204/204 [==============================] - 0s 243us/step - loss: 0.7124 - acc: 0.5637 - val_loss: 0.7565 - val_acc: 0.5000\n",
      "Epoch 12/30\n",
      "204/204 [==============================] - 0s 252us/step - loss: 0.6923 - acc: 0.5588 - val_loss: 0.7457 - val_acc: 0.5000\n",
      "Epoch 13/30\n",
      "204/204 [==============================] - 0s 275us/step - loss: 0.6853 - acc: 0.5686 - val_loss: 0.7399 - val_acc: 0.4808\n",
      "Epoch 14/30\n",
      "204/204 [==============================] - 0s 280us/step - loss: 0.6802 - acc: 0.5784 - val_loss: 0.7351 - val_acc: 0.4615\n",
      "Epoch 15/30\n",
      "204/204 [==============================] - 0s 246us/step - loss: 0.6756 - acc: 0.5784 - val_loss: 0.7314 - val_acc: 0.4615\n",
      "Epoch 16/30\n",
      "204/204 [==============================] - 0s 226us/step - loss: 0.6730 - acc: 0.5735 - val_loss: 0.7278 - val_acc: 0.4615\n",
      "Epoch 17/30\n",
      "204/204 [==============================] - 0s 275us/step - loss: 0.6692 - acc: 0.5833 - val_loss: 0.7265 - val_acc: 0.4808\n",
      "Epoch 18/30\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.6673 - acc: 0.5784 - val_loss: 0.7246 - val_acc: 0.5000\n",
      "Epoch 19/30\n",
      "204/204 [==============================] - 0s 252us/step - loss: 0.6645 - acc: 0.5882 - val_loss: 0.7244 - val_acc: 0.5192\n",
      "Epoch 20/30\n",
      "204/204 [==============================] - 0s 250us/step - loss: 0.6621 - acc: 0.5931 - val_loss: 0.7260 - val_acc: 0.5192\n",
      "Epoch 21/30\n",
      "204/204 [==============================] - 0s 257us/step - loss: 0.6594 - acc: 0.5931 - val_loss: 0.7284 - val_acc: 0.5192\n",
      "Epoch 22/30\n",
      "204/204 [==============================] - 0s 219us/step - loss: 0.6570 - acc: 0.6078 - val_loss: 0.7310 - val_acc: 0.5192\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 1.2948 - acc: 0.4265 - val_loss: 0.8864 - val_acc: 0.3846\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.7702 - acc: 0.5000 - val_loss: 0.9150 - val_acc: 0.4423\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 324us/step - loss: 0.8255 - acc: 0.5294 - val_loss: 0.9580 - val_acc: 0.4423\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 291us/step - loss: 0.7498 - acc: 0.5343 - val_loss: 0.8002 - val_acc: 0.4231\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 269us/step - loss: 0.7109 - acc: 0.5196 - val_loss: 0.7880 - val_acc: 0.3846\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.7336 - acc: 0.5000 - val_loss: 0.7763 - val_acc: 0.4423\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 294us/step - loss: 0.7099 - acc: 0.5343 - val_loss: 0.7854 - val_acc: 0.4231\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 218us/step - loss: 0.6991 - acc: 0.5637 - val_loss: 0.7863 - val_acc: 0.4423\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.6913 - acc: 0.5784 - val_loss: 0.7592 - val_acc: 0.4231\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 260us/step - loss: 0.6848 - acc: 0.5539 - val_loss: 0.7439 - val_acc: 0.4808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "204/204 [==============================] - 0s 244us/step - loss: 0.6824 - acc: 0.5686 - val_loss: 0.7488 - val_acc: 0.4615\n",
      "Epoch 12/30\n",
      "204/204 [==============================] - 0s 250us/step - loss: 0.6754 - acc: 0.5931 - val_loss: 0.7375 - val_acc: 0.4615\n",
      "Epoch 13/30\n",
      "204/204 [==============================] - 0s 241us/step - loss: 0.6661 - acc: 0.5833 - val_loss: 0.7157 - val_acc: 0.4615\n",
      "Epoch 14/30\n",
      "204/204 [==============================] - 0s 221us/step - loss: 0.6648 - acc: 0.5882 - val_loss: 0.7129 - val_acc: 0.4423\n",
      "Epoch 15/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.6665 - acc: 0.5882 - val_loss: 0.7070 - val_acc: 0.4808\n",
      "Epoch 16/30\n",
      "204/204 [==============================] - 0s 247us/step - loss: 0.6598 - acc: 0.6127 - val_loss: 0.7168 - val_acc: 0.5000\n",
      "Epoch 17/30\n",
      "204/204 [==============================] - 0s 238us/step - loss: 0.6601 - acc: 0.6225 - val_loss: 0.7036 - val_acc: 0.5000\n",
      "Epoch 18/30\n",
      "204/204 [==============================] - 0s 253us/step - loss: 0.6596 - acc: 0.6029 - val_loss: 0.6882 - val_acc: 0.6538\n",
      "Epoch 19/30\n",
      "204/204 [==============================] - 0s 228us/step - loss: 0.6556 - acc: 0.5882 - val_loss: 0.7052 - val_acc: 0.5000\n",
      "Epoch 20/30\n",
      "204/204 [==============================] - 0s 252us/step - loss: 0.6562 - acc: 0.6127 - val_loss: 0.7057 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "204/204 [==============================] - 0s 258us/step - loss: 0.6545 - acc: 0.5980 - val_loss: 0.6925 - val_acc: 0.5962\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 15ms/step - loss: 0.8563 - acc: 0.5833 - val_loss: 0.7374 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 254us/step - loss: 0.6757 - acc: 0.5735 - val_loss: 0.6505 - val_acc: 0.6154\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 275us/step - loss: 0.6927 - acc: 0.5196 - val_loss: 0.6719 - val_acc: 0.5769\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 266us/step - loss: 0.6719 - acc: 0.6176 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 264us/step - loss: 0.6809 - acc: 0.6078 - val_loss: 0.6767 - val_acc: 0.5577\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 15ms/step - loss: 5.4659 - acc: 0.4951 - val_loss: 4.7437 - val_acc: 0.5192\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 4.5959 - acc: 0.4902 - val_loss: 3.3848 - val_acc: 0.5192\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 438us/step - loss: 3.0517 - acc: 0.4902 - val_loss: 1.8788 - val_acc: 0.5000\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 412us/step - loss: 1.4262 - acc: 0.5000 - val_loss: 0.7472 - val_acc: 0.4038\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.7742 - acc: 0.5000 - val_loss: 0.8447 - val_acc: 0.4808\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 239us/step - loss: 0.9453 - acc: 0.5196 - val_loss: 0.8278 - val_acc: 0.5192\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 0.8167 - acc: 0.5245 - val_loss: 0.6907 - val_acc: 0.5385\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.7107 - acc: 0.4902 - val_loss: 0.7155 - val_acc: 0.4808\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 446us/step - loss: 0.7258 - acc: 0.4853 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.7018 - acc: 0.5000 - val_loss: 0.6837 - val_acc: 0.5769\n",
      "Epoch 11/30\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.7007 - acc: 0.5539 - val_loss: 0.6814 - val_acc: 0.5962\n",
      "Epoch 12/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 0.6944 - acc: 0.5588 - val_loss: 0.6811 - val_acc: 0.6154\n",
      "Epoch 13/30\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.6931 - acc: 0.5441 - val_loss: 0.6805 - val_acc: 0.6346\n",
      "Epoch 14/30\n",
      "204/204 [==============================] - 0s 253us/step - loss: 0.6927 - acc: 0.5196 - val_loss: 0.6798 - val_acc: 0.6538\n",
      "Epoch 15/30\n",
      "204/204 [==============================] - 0s 228us/step - loss: 0.6909 - acc: 0.5245 - val_loss: 0.6776 - val_acc: 0.6731\n",
      "Epoch 16/30\n",
      "204/204 [==============================] - 0s 254us/step - loss: 0.6896 - acc: 0.5490 - val_loss: 0.6754 - val_acc: 0.6538\n",
      "Epoch 17/30\n",
      "204/204 [==============================] - 0s 239us/step - loss: 0.6948 - acc: 0.5098 - val_loss: 0.6792 - val_acc: 0.5577\n",
      "Epoch 18/30\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.6865 - acc: 0.5441 - val_loss: 0.6716 - val_acc: 0.6154\n",
      "Epoch 19/30\n",
      "204/204 [==============================] - 0s 456us/step - loss: 0.6849 - acc: 0.5882 - val_loss: 0.6700 - val_acc: 0.6154\n",
      "Epoch 20/30\n",
      "204/204 [==============================] - 0s 367us/step - loss: 0.6856 - acc: 0.5882 - val_loss: 0.6703 - val_acc: 0.6346\n",
      "Epoch 21/30\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.6815 - acc: 0.5637 - val_loss: 0.6671 - val_acc: 0.6154\n",
      "Epoch 22/30\n",
      "204/204 [==============================] - 0s 282us/step - loss: 0.6963 - acc: 0.5000 - val_loss: 0.6688 - val_acc: 0.6346\n",
      "Epoch 23/30\n",
      "204/204 [==============================] - 0s 283us/step - loss: 0.6864 - acc: 0.5833 - val_loss: 0.6645 - val_acc: 0.5962\n",
      "Epoch 24/30\n",
      "204/204 [==============================] - 0s 280us/step - loss: 0.6757 - acc: 0.5784 - val_loss: 0.6679 - val_acc: 0.6346\n",
      "Epoch 25/30\n",
      "204/204 [==============================] - 0s 279us/step - loss: 0.6772 - acc: 0.5392 - val_loss: 0.6648 - val_acc: 0.6731\n",
      "Epoch 26/30\n",
      "204/204 [==============================] - 0s 251us/step - loss: 0.6733 - acc: 0.5784 - val_loss: 0.6611 - val_acc: 0.5962\n",
      "Epoch 27/30\n",
      "204/204 [==============================] - 0s 288us/step - loss: 0.6835 - acc: 0.6029 - val_loss: 0.6611 - val_acc: 0.5962\n",
      "Epoch 28/30\n",
      "204/204 [==============================] - 0s 290us/step - loss: 0.6716 - acc: 0.5980 - val_loss: 0.6655 - val_acc: 0.5769\n",
      "Epoch 29/30\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.6726 - acc: 0.5441 - val_loss: 0.6654 - val_acc: 0.5769\n",
      "Epoch 30/30\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.6721 - acc: 0.5686 - val_loss: 0.6597 - val_acc: 0.6923\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 16ms/step - loss: 3.5350 - acc: 0.5245 - val_loss: 3.3719 - val_acc: 0.4615\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 293us/step - loss: 2.4469 - acc: 0.5294 - val_loss: 2.0340 - val_acc: 0.5000\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 289us/step - loss: 1.4067 - acc: 0.5441 - val_loss: 0.8804 - val_acc: 0.5385\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 240us/step - loss: 0.7795 - acc: 0.5147 - val_loss: 0.7287 - val_acc: 0.5385\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 339us/step - loss: 0.8865 - acc: 0.4559 - val_loss: 0.6912 - val_acc: 0.5769\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.7384 - acc: 0.5147 - val_loss: 0.7958 - val_acc: 0.5385\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.7502 - acc: 0.5735 - val_loss: 0.7673 - val_acc: 0.5385\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 278us/step - loss: 0.7131 - acc: 0.5490 - val_loss: 0.6999 - val_acc: 0.5385\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 3.0647 - acc: 0.5343 - val_loss: 3.1590 - val_acc: 0.3846\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 293us/step - loss: 1.9770 - acc: 0.5441 - val_loss: 1.6291 - val_acc: 0.4231\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 270us/step - loss: 0.9507 - acc: 0.5588 - val_loss: 0.6743 - val_acc: 0.6346\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 286us/step - loss: 0.8211 - acc: 0.4559 - val_loss: 0.7109 - val_acc: 0.6154\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 258us/step - loss: 0.7638 - acc: 0.4657 - val_loss: 0.6975 - val_acc: 0.5385\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 276us/step - loss: 0.6952 - acc: 0.5833 - val_loss: 0.8068 - val_acc: 0.5192\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 1.9234 - acc: 0.4755 - val_loss: 1.2609 - val_acc: 0.5192\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 1.1068 - acc: 0.4363 - val_loss: 0.6855 - val_acc: 0.5962\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 245us/step - loss: 0.7156 - acc: 0.4706 - val_loss: 0.6997 - val_acc: 0.5385\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 260us/step - loss: 0.7770 - acc: 0.5049 - val_loss: 0.7361 - val_acc: 0.5385\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 0.7559 - acc: 0.5147 - val_loss: 0.6722 - val_acc: 0.5769\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 238us/step - loss: 0.6971 - acc: 0.5441 - val_loss: 0.6469 - val_acc: 0.5769\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 259us/step - loss: 0.7021 - acc: 0.4951 - val_loss: 0.6571 - val_acc: 0.6538\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 277us/step - loss: 0.6899 - acc: 0.5343 - val_loss: 0.6488 - val_acc: 0.5385\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 237us/step - loss: 0.6801 - acc: 0.5931 - val_loss: 0.6525 - val_acc: 0.5577\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 7.0119 - acc: 0.5049 - val_loss: 7.4468 - val_acc: 0.4808\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 249us/step - loss: 6.8983 - acc: 0.5049 - val_loss: 7.4158 - val_acc: 0.4808\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 263us/step - loss: 6.7849 - acc: 0.5049 - val_loss: 7.3810 - val_acc: 0.4808\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 254us/step - loss: 6.6610 - acc: 0.5049 - val_loss: 7.3253 - val_acc: 0.4808\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 249us/step - loss: 6.5010 - acc: 0.5049 - val_loss: 7.2747 - val_acc: 0.4808\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 6.3033 - acc: 0.5049 - val_loss: 7.2099 - val_acc: 0.4808\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 266us/step - loss: 6.0538 - acc: 0.5049 - val_loss: 7.1260 - val_acc: 0.4808\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 252us/step - loss: 5.7721 - acc: 0.5000 - val_loss: 6.9837 - val_acc: 0.4808\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 263us/step - loss: 5.4033 - acc: 0.4951 - val_loss: 6.6688 - val_acc: 0.4808\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 253us/step - loss: 4.7766 - acc: 0.4951 - val_loss: 5.9872 - val_acc: 0.4615\n",
      "Epoch 11/30\n",
      "204/204 [==============================] - 0s 238us/step - loss: 3.8988 - acc: 0.5000 - val_loss: 4.5326 - val_acc: 0.4808\n",
      "Epoch 12/30\n",
      "204/204 [==============================] - 0s 245us/step - loss: 2.9089 - acc: 0.4853 - val_loss: 3.4644 - val_acc: 0.4615\n",
      "Epoch 13/30\n",
      "204/204 [==============================] - 0s 242us/step - loss: 2.2043 - acc: 0.4608 - val_loss: 2.5683 - val_acc: 0.4615\n",
      "Epoch 14/30\n",
      "204/204 [==============================] - 0s 266us/step - loss: 1.6164 - acc: 0.4755 - val_loss: 1.7995 - val_acc: 0.4038\n",
      "Epoch 15/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 1.1290 - acc: 0.4412 - val_loss: 1.2032 - val_acc: 0.3654\n",
      "Epoch 16/30\n",
      "204/204 [==============================] - 0s 243us/step - loss: 0.8337 - acc: 0.4069 - val_loss: 0.8604 - val_acc: 0.2692\n",
      "Epoch 17/30\n",
      "204/204 [==============================] - 0s 244us/step - loss: 0.7323 - acc: 0.4755 - val_loss: 0.7763 - val_acc: 0.5192\n",
      "Epoch 18/30\n",
      "204/204 [==============================] - 0s 264us/step - loss: 0.7443 - acc: 0.5196 - val_loss: 0.7702 - val_acc: 0.5577\n",
      "Epoch 19/30\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.7472 - acc: 0.5196 - val_loss: 0.7689 - val_acc: 0.5577\n",
      "Epoch 20/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 0.7332 - acc: 0.5245 - val_loss: 0.7722 - val_acc: 0.5192\n",
      "Epoch 21/30\n",
      "204/204 [==============================] - 0s 257us/step - loss: 0.7232 - acc: 0.5196 - val_loss: 0.7810 - val_acc: 0.4423\n",
      "Epoch 22/30\n",
      "204/204 [==============================] - 0s 245us/step - loss: 0.7180 - acc: 0.5441 - val_loss: 0.7868 - val_acc: 0.3846\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/30\n",
      "204/204 [==============================] - 3s 14ms/step - loss: 3.7532 - acc: 0.5294 - val_loss: 2.6851 - val_acc: 0.3846\n",
      "Epoch 2/30\n",
      "204/204 [==============================] - 0s 255us/step - loss: 3.3088 - acc: 0.5294 - val_loss: 2.2577 - val_acc: 0.3846\n",
      "Epoch 3/30\n",
      "204/204 [==============================] - 0s 239us/step - loss: 2.7509 - acc: 0.5392 - val_loss: 1.8211 - val_acc: 0.4038\n",
      "Epoch 4/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 2.2020 - acc: 0.5441 - val_loss: 1.4023 - val_acc: 0.4423\n",
      "Epoch 5/30\n",
      "204/204 [==============================] - 0s 248us/step - loss: 1.6672 - acc: 0.5539 - val_loss: 1.0256 - val_acc: 0.5000\n",
      "Epoch 6/30\n",
      "204/204 [==============================] - 0s 256us/step - loss: 1.1846 - acc: 0.5441 - val_loss: 0.7170 - val_acc: 0.5577\n",
      "Epoch 7/30\n",
      "204/204 [==============================] - 0s 245us/step - loss: 0.8013 - acc: 0.5441 - val_loss: 0.6069 - val_acc: 0.7692\n",
      "Epoch 8/30\n",
      "204/204 [==============================] - 0s 288us/step - loss: 0.7135 - acc: 0.4461 - val_loss: 0.6947 - val_acc: 0.6154\n",
      "Epoch 9/30\n",
      "204/204 [==============================] - 0s 254us/step - loss: 0.7479 - acc: 0.4608 - val_loss: 0.6800 - val_acc: 0.6154\n",
      "Epoch 10/30\n",
      "204/204 [==============================] - 0s 258us/step - loss: 0.7210 - acc: 0.4608 - val_loss: 0.6244 - val_acc: 0.8077\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=state,stratify=y)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape = (15,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    #model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    y_train = to_categorical(y_train)\n",
    "    model.fit(X_train, y_train,epochs=30,validation_split=0.2,callbacks=[early_stopping_monitor])\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc.append(roc(y_test,y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58691406, 0.62890625, 0.65527344, 0.55957031, 0.58691406,\n",
       "       0.6484375 , 0.63574219, 0.57128906, 0.69238281, 0.65332031])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-np.array(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 1.5144 - acc: 0.5402\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 0s 209us/step - loss: 0.7996 - acc: 0.5000\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 0s 180us/step - loss: 0.7222 - acc: 0.5580\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 0s 192us/step - loss: 0.7333 - acc: 0.5536\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 0s 154us/step - loss: 0.6710 - acc: 0.5938\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 0s 131us/step - loss: 0.6725 - acc: 0.6205\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangmk/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 0s 209us/step - loss: 0.6669 - acc: 0.6116\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 0s 155us/step - loss: 0.6676 - acc: 0.6116\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 0s 149us/step - loss: 0.6579 - acc: 0.6161\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 0s 152us/step - loss: 0.6574 - acc: 0.6205\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 0s 142us/step - loss: 0.6485 - acc: 0.6250\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 0s 141us/step - loss: 0.6503 - acc: 0.6295\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 0s 144us/step - loss: 0.6570 - acc: 0.6161\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 0s 145us/step - loss: 0.6452 - acc: 0.6473\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 0s 155us/step - loss: 0.6464 - acc: 0.5938\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 0s 287us/step - loss: 0.6412 - acc: 0.6429\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 0s 186us/step - loss: 0.6377 - acc: 0.6384\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 0s 160us/step - loss: 0.6345 - acc: 0.6562\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 0s 140us/step - loss: 0.6331 - acc: 0.6429\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 0s 150us/step - loss: 0.6296 - acc: 0.6518\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 0s 177us/step - loss: 0.6380 - acc: 0.6205\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 0s 176us/step - loss: 0.6258 - acc: 0.6429\n",
      "Epoch 23/30\n",
      "224/224 [==============================] - 0s 163us/step - loss: 0.6297 - acc: 0.6429\n",
      "Epoch 24/30\n",
      "224/224 [==============================] - 0s 169us/step - loss: 0.6278 - acc: 0.6473\n",
      "Epoch 25/30\n",
      "224/224 [==============================] - 0s 154us/step - loss: 0.6211 - acc: 0.6562\n",
      "Epoch 26/30\n",
      "224/224 [==============================] - 0s 148us/step - loss: 0.6210 - acc: 0.6607\n",
      "Epoch 27/30\n",
      "224/224 [==============================] - 0s 141us/step - loss: 0.6129 - acc: 0.6473\n",
      "Epoch 28/30\n",
      "224/224 [==============================] - 0s 156us/step - loss: 0.6185 - acc: 0.6830\n",
      "Epoch 29/30\n",
      "224/224 [==============================] - 0s 196us/step - loss: 0.6144 - acc: 0.6429\n",
      "Epoch 30/30\n",
      "224/224 [==============================] - 0s 149us/step - loss: 0.6339 - acc: 0.6384\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=90,stratify=y)\n",
    "#y_train = to_categorical(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "model.fit(X_train, y_train,epochs=30,callbacks=[early_stopping_monitor])\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.2781093e-01, 9.6576536e-01, 4.9527165e-01, 7.8700435e-01,\n",
       "       3.9921245e-01, 3.5112223e-01, 9.9916542e-01, 9.7007430e-01,\n",
       "       1.4523604e-07, 1.0000000e+00, 2.3089497e-01, 8.6935169e-01,\n",
       "       1.0064879e-01, 9.9999309e-01, 8.3719021e-01, 3.3655077e-01,\n",
       "       9.9711955e-01, 7.1858209e-01, 8.2754129e-01, 1.4469554e-02,\n",
       "       8.5599221e-02, 1.8053779e-01, 5.2807128e-01, 9.9986053e-01,\n",
       "       4.6354693e-01, 2.5273836e-01, 9.4924819e-01, 1.1996118e-05,\n",
       "       9.9115258e-01, 9.9188954e-01, 9.9693966e-01, 9.9981266e-01,\n",
       "       5.6586689e-01, 2.0685905e-01, 2.4357524e-03, 1.0780092e-02,\n",
       "       1.0451220e-03, 2.5900088e-02, 5.6790650e-01, 7.7393037e-01,\n",
       "       5.9709424e-01, 5.6371850e-01, 7.7456957e-01, 5.6853676e-01,\n",
       "       8.5441127e-02, 3.2835554e-02, 1.9453971e-01, 3.7325958e-12,\n",
       "       9.9571770e-01, 9.2963201e-01, 1.0000000e+00, 3.0722255e-03,\n",
       "       5.5444032e-01, 2.9924141e-08, 4.1801161e-01, 9.8528636e-01,\n",
       "       1.0000000e+00, 7.5642481e-02, 5.1396197e-01, 9.9999011e-01,\n",
       "       9.9185479e-01, 9.4687035e-03, 9.2545313e-01, 1.4253713e-09,\n",
       "       2.5544217e-01, 4.3936107e-01, 2.8905544e-01, 9.9998498e-01,\n",
       "       9.7163230e-01, 9.5147371e-01, 2.1070935e-02, 7.7317882e-01,\n",
       "       9.9999988e-01, 1.7957966e-05, 9.1320986e-01, 3.1462168e-06,\n",
       "       2.2905734e-01, 4.0839258e-01, 1.6421844e-01, 5.0206113e-01,\n",
       "       3.8849607e-01, 1.7290459e-04, 3.4792963e-01, 3.7018852e-03,\n",
       "       2.2859506e-03, 7.7821754e-02, 1.0000000e+00, 5.3551131e-01,\n",
       "       9.9413067e-01, 4.7151942e-02, 1.4368734e-02, 9.7768579e-04,\n",
       "       9.7339690e-01, 9.3800837e-01, 9.1076970e-01, 1.3528724e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4748263888888889"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc(y_test, y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
